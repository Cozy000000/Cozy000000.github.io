---
permalink: /
title: ''
excerpt: ''
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am **Zhiyi Chen** (é™ˆå¿—å±¹), an Undergraduate Student. candidate in Artificial Intelligence Thrust at the Hong Kong University of Science and Technology (Guangzhou). Under the guidance of [Prof. Zeyi Wen](https://zeyiwen.github.io/). My research interests are in the fields of NLP, efficient large language models, HPO, and machine learning.


<!-- **Research Interests**

My research focuses on enhancing the efficiency and accessibility of deep learning models, particularly in the following areas:

- Model Compression: Exploring pruning, quantization, and knowledge distillation techniques to reduce model size and computational demands.
- Efficient Large Language Models: Optimizing LLM training and inference through innovative architectures and deployment strategies.
- Automated Machine Learning (AutoML): Developing methods to streamline the ML pipeline, from architecture search to hyperparameter optimization.

My goal is to contribute significantly to the development of more efficient and accessible machine learning systems. Through my research, I strive to push the boundaries of what's possible in model compression, efficient large language models, and automated machine learning. If you share similar interests or would like to discuss potential collaborations, I warmly invite you to reach out to me. I'm always eager to connect with fellow researchers and industry professionals to exchange ideas and explore new opportunities in this exciting field. -->

# ğŸ”¥ News
- [2025.8] &nbsp;ğŸ‰ğŸ‰ One papers accepted by EMNLP'25 main track, and another paper accepted by CIKM'25.

## ğŸ“– Educations

- _2023.09 - now, Hong Kong University of Science and Technology(Guang Zhou) Undergraduate

  - Advisor: Prof. Zeyi Wen
  - Research Interests: NLP, LLM, HPO
  <!-- - Achievement: Outstanding Graduate -->

- _2020.09 - 2023.06_, Student in Chengdu No.7 High School

## ğŸ’» Internship



<!-- # ğŸ“• Teaching

- Teaching Assistant at HKBU
  - 2023 Spring Semester, COMP7940 Cloud Computing
  - 2022 Fall Semester, COMP7015 Artiï¬cial Intelligence
  - 2022 Spring Semester, COMP 7550 IT Project Management
  - 2021 Fall Semester, COMP 7015, Artificial Intelligence
  - 2021 Spring Semester, COMP 7930, Big Data Analytics -->

# ğŸ‘” Professional Activities

- **2025**:
  - _Conferences_: CIKM, EMNLP
  - _Journals_: 


# ğŸ– Honors and Awards
- 2025, Gold Medal in iGEM
- 2025, Bronze Medal, The 50th ICPC Asia Regional Contest (Nanjing)
- 2025, The Second Class Prize of ASC student supercomputer challenge
- 2024, Bronze Medal, The 49th ICPC Asia Regional Contest (Shanghai)
- 2024, Merit Research award in 2024 HKUST(GZ) Undergraduate Research Program
- 2024, The Second Class Prize of ASC student supercomputer challenge
- 2024, Bronze Medal, China Collegiate Programming Contest (CCPC) National Invitational (Shandong)
- 2021, First Prize in the National Biology League for High School Students (Sichuan Province Rank 26) 

# ğŸ“ Publications

Selected papers: EMNLP(Oralx1), CIKMx1.


- Xu, Yuebin, **Zhiyi Chen**, and Zeyi Wen. EcoTune: Token-Efficient Multi-Fidelity Hyperparameter Optimization for Large Language Model Inference. In EMNLP2025

- Xu, Yuebin, Xuemei Peng, **Zhiyi Chen**, and Zeyi Wen. KALE: Knowledge Aggregation for Label-free Model Enhancement. In CIKM2025

<!--
[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.
</div>
</div> -->

<!-- - [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020** -->

<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=WLf9b66ilDZRnTA1p3jOxQp-T_d738h0cJKCEfhFM8s&cl=ffffff&w=a"></script>
